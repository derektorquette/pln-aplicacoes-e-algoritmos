{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/derektorquette/pln-com-deep-learning-ia-expert/blob/main/tradu%C3%A7%C3%A3o_de_en_para_pt_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9JJ7FBw84tG"
      },
      "source": [
        "# Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbcvtPlp3YWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c66a16-cea6-4b7e-d303-375be29856a9"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import zipfile\n",
        "import random\n",
        "from google.colab import drive\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQN8jwx48_yU"
      },
      "source": [
        "# Etapa 2: Pré-processamento dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPlOT-2mlw0r"
      },
      "source": [
        "## Carregamento da base de dados\n",
        "\n",
        "- Bases de dados: https://www.statmt.org/europarl/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQpbl1pXCR0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c781fe-f7d9-46a6-cf04-ed9e629e6dcc"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwnapSjqjIEN"
      },
      "source": [
        "path = '/content/drive/MyDrive/CURSOS LIVRES FORMAÇÃO COMPLEMENTAR/3. Udemy/Processamento de Linguagem Natural com Deep Learning/Seção 4 e 5 - Arquitetura Tranformer /pt-en.zip'\n",
        "zip_object = zipfile.ZipFile(file = path, mode = 'r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jFJaq1-OpPS"
      },
      "source": [
        "with open('/content/pt-en/europarl-v7.pt-en.en', mode='r', encoding='utf-8') as f:\n",
        "  europarl_en = f.read()\n",
        "with open('/content/pt-en/europarl-v7.pt-en.pt', mode='r', encoding='utf-8') as f:\n",
        "  europarl_pt = f.read ()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kGhnz3UO_K3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ee0d8102-699d-43bd-ba5e-eba88196cf27"
      },
      "source": [
        "europarl_en[0:100]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Resumption of the session\\nI declare resumed the session of the European Parliament adjourned on Frid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5eZYjTiPM5k"
      },
      "source": [
        "en = europarl_en.split('\\n')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eQ2zW5NPSqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70540761-f718-4dfd-a8a7-7c9a97548955"
      },
      "source": [
        "len(en) # total de frases"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1960408"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJSDFBzFPWQa"
      },
      "source": [
        "en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rVFAtegPeV9"
      },
      "source": [
        "pt = europarl_pt.split('\\n')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_DzVSHJPvxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb426d85-c5ef-4e22-acfe-63eb4dccdc18"
      },
      "source": [
        "len(pt)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1960408"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JzKYspxPzF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468d6004-526f-4400-cead-bec32df304d1"
      },
      "source": [
        "for _ in range(5):\n",
        "  print('-----')\n",
        "  i = random.randint(0, len(en) - 1)\n",
        "  print(en[i])\n",
        "  print(pt[i])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "Let us never forget how much the European Union is already doing and how great is its contribution to greater fairness for them.\n",
            "Não esqueçamos nunca tudo o que a União Europeia já estar a fazer, nem a importância do seu contributo para que estes países gozem de uma maior equidade.\n",
            "-----\n",
            "On 2 June 2006 – just two weeks ago – the Commission submitted to the Tunisian authorities the draft internal regulation of the abovementioned subcommittee and is awaiting a reply from the Tunisian side.\n",
            "Em 2 e Junho de 2006 – há apenas duas semanas – a Comissão apresentou às autoridades tunisinas o projecto de regulamento interno da referida subcomissão e aguarda a resposta da parte tunisina.\n",
            "-----\n",
            "The area is currently governed by national laws, and citizens are poorly informed with regard to the options, reimbursement and possible treatment abroad.\n",
            "Actualmente, esta matéria é regida apenas pelas legislações nacionais, estando os cidadãos pouco informados sobre as opções à sua disposição, sobre os reembolsos e sobre os possíveis tratamentos no estrangeiro.\n",
            "-----\n",
            "My country's new constitution does not apply such discrimination.\n",
            "A nova constituição do meu país não aplica esta discriminação.\n",
            "-----\n",
            "We are being aided by the sustained and shared commitment of Parliament to that end and we are grateful for that support.\n",
            "O empenhamento constante do Parlamento nesse sentido, tal como o nosso, representa uma ajuda para nós e estamos gratos pelo apoio que nos tem sido dado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEFw0D2vP_Dl"
      },
      "source": [
        "## Limpeza dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FstFwA_qQf--"
      },
      "source": [
        "corpus_en = europarl_en\n",
        "corpus_en = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_en)\n",
        "corpus_en = re.sub(r\".\\$\\$\\$\", '', corpus_en)\n",
        "corpus_en = re.sub(r\" +\", \" \", corpus_en)\n",
        "corpus_en = corpus_en.split('\\n')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfCfrBI9RclA"
      },
      "source": [
        "corpus_pt = europarl_pt\n",
        "corpus_pt = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_pt)\n",
        "corpus_pt = re.sub(r\".\\$\\$\\$\", '', corpus_pt)\n",
        "corpus_pt = re.sub(r\" +\", \" \", corpus_pt)\n",
        "corpus_pt = corpus_pt.split('\\n')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHFALYvTRlnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8e6eec-ca3d-40fa-8ebf-641d54bc9b8b"
      },
      "source": [
        "len(corpus_en)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1960408"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztnDRbp7RyUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797164c6-c3ca-448a-b74c-3b1b6ed6338e"
      },
      "source": [
        "len(corpus_pt)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1960408"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Y9v8-Tozl2"
      },
      "source": [
        "\n",
        "## Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2P1ghMRSY8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0304fe8b-8373-4a7c-a6f7-4eac90337480"
      },
      "source": [
        "2**13"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8192"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpv4D_w3SHsV"
      },
      "source": [
        "# Atualização MAR-2024\n",
        "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_en, target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbs8ymTsTYbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d3b4214-2192-4854-af7e-12a7d180a303"
      },
      "source": [
        "tokenizer_en.vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8191"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4W7---rTeB5"
      },
      "source": [
        "# Atualização MAR-2024\n",
        "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_pt, target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8pvMbjfU6m8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f38ccc-f696-4c80-ca9e-e646a05d46c1"
      },
      "source": [
        "tokenizer_pt.vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8116"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBK7J_fwVB-K"
      },
      "source": [
        "vocab_size_en = tokenizer_en.vocab_size + 2\n",
        "vocab_size_pt = tokenizer_pt.vocab_size + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUg9yHNnVR0o"
      },
      "source": [
        "inputs = [[vocab_size_en - 2] + tokenizer_en.encode(sentence) + [vocab_size_en - 1] for sentence in corpus_en]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKUVY0_OVpoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1b3a66-4fc1-41a3-fbc4-bb59c5790eb8"
      },
      "source": [
        "for _ in range(5):\n",
        "  print(inputs[random.randint(0, len(inputs) - 1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8191, 25, 6690, 7967, 9, 2904, 6113, 2, 5, 20, 9, 19, 445, 4, 2120, 7981, 8192]\n",
            "[8191, 25, 179, 9, 1223, 7981, 8192]\n",
            "[8191, 47, 9, 7, 2161, 2, 2383, 3192, 7981, 8192]\n",
            "[8191, 2963, 64, 2900, 8, 20, 9, 77, 27, 1437, 553, 24, 2651, 639, 2, 1093, 2, 973, 5, 3402, 224, 367, 112, 517, 1567, 224, 8, 64, 26, 1512, 4, 1, 310, 3, 23, 913, 7998, 8192]\n",
            "[8191, 7048, 2, 11, 137, 1, 71, 35, 1283, 8, 29, 7755, 801, 12, 35, 96, 1447, 261, 12, 264, 3, 1, 255, 138, 2, 5, 690, 16, 161, 6, 1, 329, 10, 5160, 2869, 7981, 8192]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUNLcWH1WQ5d"
      },
      "source": [
        "outputs = [[vocab_size_pt - 2] + tokenizer_pt.encode(sentence) + [vocab_size_pt - 1] for sentence in corpus_pt]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi77Y1u-W5Sb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b84830-2574-43a4-e900-02733a04c438"
      },
      "source": [
        "for _ in range(5):\n",
        "  print(outputs[random.randint(0, len(outputs) - 1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8116, 322, 3111, 1, 2626, 279, 1763, 13, 598, 33, 3, 2738, 2065, 1, 4, 61, 47, 106, 1851, 7968, 5521, 3, 185, 166, 54, 7905, 94, 5, 4, 61, 37, 106, 1851, 7968, 5521, 3, 20, 283, 7, 957, 8, 1442, 4378, 1975, 1, 10, 7254, 1154, 6801, 7957, 1, 328, 2707, 347, 3, 4775, 454, 7906, 8117]\n",
            "[8116, 6871, 201, 4, 3, 7807, 152, 4168, 5, 2660, 377, 4732, 7977, 7906, 8117]\n",
            "[8116, 545, 403, 197, 83, 24, 2774, 8, 1056, 15, 5579, 15, 3302, 4663, 7892, 28, 5925, 135, 1, 1056, 160, 4, 2611, 202, 1, 1253, 1, 919, 4326, 11, 4806, 1687, 29, 83, 6, 672, 8, 1928, 7, 298, 6744, 7906, 8117]\n",
            "[8116, 507, 18, 3, 60, 2, 1701, 8, 1741, 7906, 8117]\n",
            "[8116, 36, 1155, 997, 7, 1703, 58, 6, 2779, 5, 6, 2956, 109, 37, 3878, 29, 5, 277, 228, 3259, 14, 504, 284, 5, 28, 5342, 42, 6, 363, 328, 228, 76, 335, 1165, 5, 14, 741, 6415, 11, 59, 470, 7906, 8117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG6AlcFMpC5C"
      },
      "source": [
        "## Remoção de sentenças muito longas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beBpYgWmX7Ug"
      },
      "source": [
        "max_length = 15\n",
        "idx_to_remove = [count for count, sent in enumerate(inputs) if len(sent) > max_length]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Y51ZGxYgQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfda3ad7-8e9a-4d30-9351-06d7beac81bf"
      },
      "source": [
        "len(idx_to_remove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1685300"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gvs2dnOYxmd"
      },
      "source": [
        "0 - 1\n",
        "1 - 13\n",
        "2 - 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhGXWxrKYq0d"
      },
      "source": [
        "for idx in reversed(idx_to_remove):\n",
        "  del inputs[idx]\n",
        "  del outputs[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLFvIk5LaUvL"
      },
      "source": [
        "idx_to_remove = [count for count, sent in enumerate(outputs) if len(sent) > max_length]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF9Uyfizcn4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0e147d-09ea-41c5-dbe3-671e6beb1a73"
      },
      "source": [
        "len(idx_to_remove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66118"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWdKUhYOcw66"
      },
      "source": [
        "for idx in reversed(idx_to_remove):\n",
        "  del inputs[idx]\n",
        "  del outputs[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWgpUnGGc0_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa643ae-860a-482e-a1a4-1e75b9004eee"
      },
      "source": [
        "len(inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "208990"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ncA-qtvc3mU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fdea24-58a3-4444-bfb3-ccfa41fe4e3d"
      },
      "source": [
        "len(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "208990"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypm8h5aZQTZ1"
      },
      "source": [
        "## Padding e batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdABR5kof67b"
      },
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, value=0, padding = 'post', maxlen=max_length)\n",
        "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs, value=0, padding = 'post', maxlen=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQkr9qj2ge1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acba45fc-ad20-4b7b-cd5f-0ab928c5999a"
      },
      "source": [
        "for _ in range(5):\n",
        "  print(outputs[random.randint(0, len(outputs) - 1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8116 1438 5889 7657 1075   19    2  365   49 4393 7906 8117    0    0\n",
            "    0]\n",
            "[8116 3562 1111    1  700    1 1051    6  761 7906 8117    0    0    0\n",
            "    0]\n",
            "[8116   30  410  408  363 1405 7906 8117    0    0    0    0    0    0\n",
            "    0]\n",
            "[8116   90  109  959 7893 8117    0    0    0    0    0    0    0    0\n",
            "    0]\n",
            "[8116 1984    6  898    1   17  744 1003 3977 7906 8117    0    0    0\n",
            "    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgh_KgNJPlvf"
      },
      "source": [
        "from_tensor_slices: https://www.geeksforgeeks.org/tensorflow-tf-data-dataset-from_tensor_slices/\n",
        "\n",
        "cache e prefetch: https://www.tensorflow.org/guide/data_performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTL-bfDsgoo0"
      },
      "source": [
        "batch_size = 64\n",
        "buffer_size = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycT0YqydRcUd"
      },
      "source": [
        "# Etapa 3: Construção do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SBoH8G4XyR9"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G9C3ucmJ86I"
      },
      "source": [
        "Positional encoding:\n",
        "\n",
        "$PE_{(pos,2i)} =\\sin(pos/10000^{2i/dmodel})$\n",
        "\n",
        "$PE_{(pos,2i+1)} =\\cos(pos/10000^{2i/dmodel})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfzJfp_RmhyX"
      },
      "source": [
        "- The positional encodings have the same dimension dmodel\n",
        "as the embeddings, so that the two can be summed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2wc6sYlX0dr"
      },
      "source": [
        "class PositionalEncoding(layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "      super(PositionalEncoding, self).__init__()\n",
        "\n",
        "    def get_angles(self, pos, i, d_model):\n",
        "      angles = 1 / np.power(10000., (2*(i // 2)) / np.float32(d_model))\n",
        "      return pos * angles # (seq_lenght, d_model)\n",
        "\n",
        "    def call(self, inputs):\n",
        "      seq_lenght = inputs.shape.as_list()[-2]\n",
        "      d_model = inputs.shape.as_list()[-1]\n",
        "      angles = self.get_angles(np.arange(seq_lenght)[:, np.newaxis],\n",
        "                               np.arange(d_model)[np.newaxis, :], d_model)\n",
        "      angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "      angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
        "      pos_encoding = angles[np.newaxis, ...]\n",
        "      return inputs + tf.cast(pos_encoding, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcw8YIQqRhOJ"
      },
      "source": [
        "## Mecanismo de atenção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sffhwwvX-wj"
      },
      "source": [
        "### Cálculo da atenção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VBuW6lESLDX"
      },
      "source": [
        "$Attention(Q, K, V ) = \\text{softmax}\\left(\\dfrac{QK^T}{\\sqrt{d_k}}\\right)V $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rEoCNJURbrT"
      },
      "source": [
        "def scaled_dot_product_attention(queries, keys, values, mask):\n",
        "  product = tf.matmul(queries, keys, transpose_b=True)\n",
        "  keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
        "  scaled_product = product / tf.math.sqrt(keys_dim)\n",
        "\n",
        "  if mask is not None:\n",
        "    scaled_product += (mask * -1e9) # 0.0000000001\n",
        "\n",
        "  attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
        "  return attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MjtvXrfYEx7"
      },
      "source": [
        "### Multi-head attention sublayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvq4I9uTX5p7"
      },
      "source": [
        "class MultiHeadAttention(layers.Layer):\n",
        "\n",
        "    def __init__(self, nb_proj):\n",
        "      super(MultiHeadAttention, self).__init__()\n",
        "      self.nb_proj = nb_proj\n",
        "\n",
        "    def build(self, input_shape):\n",
        "      self.d_model = input_shape[-1]\n",
        "      assert self.d_model % self.nb_proj == 0\n",
        "\n",
        "      self.d_proj = self.d_model // self.nb_proj\n",
        "\n",
        "      self.query_lin = layers.Dense(units = self.d_model)\n",
        "      self.key_lin = layers.Dense(units = self.d_model)\n",
        "      self.value_lin = layers.Dense(units = self.d_model)\n",
        "\n",
        "      self.final_lin = layers.Dense(units = self.d_model)\n",
        "\n",
        "    def split_proj(self, inputs, batch_size): # inputs: (batch_size, seq_lenght, d_model)\n",
        "      shape = (batch_size, -1, self.nb_proj, self.d_proj)\n",
        "      splited_inputs = tf.reshape(inputs, shape = shape) # (batch_size, seq_lenght, nb_proj, d_proj)\n",
        "      return tf.transpose(splited_inputs, perm=[0, 2, 1, 3]) # (batch_size, nb_proj, seq_lenght, d_proj)\n",
        "\n",
        "    def call(self, queries, keys, values, mask):\n",
        "      batch_size = tf.shape(queries)[0]\n",
        "\n",
        "      queries = self.query_lin(queries)\n",
        "      keys = self.key_lin(keys)\n",
        "      values = self.value_lin(values)\n",
        "\n",
        "      queries = self.split_proj(queries, batch_size)\n",
        "      keys = self.split_proj(keys, batch_size)\n",
        "      values = self.split_proj(values, batch_size)\n",
        "\n",
        "      attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
        "\n",
        "      attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "      concat_attention = tf.reshape(attention, shape=(batch_size, -1, self.d_model))\n",
        "\n",
        "      outputs = self.final_lin(concat_attention)\n",
        "\n",
        "      return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiyuHe1OeT5N"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV0ZMH7KT_KZ"
      },
      "source": [
        "class EncoderLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, FFN_units, nb_proj, dropout_rate):\n",
        "      super(EncoderLayer, self).__init__()\n",
        "      self.FFN_units = FFN_units\n",
        "      self.nb_proj = nb_proj\n",
        "      self.dropout_rate = dropout_rate\n",
        "\n",
        "    def build(self, input_shape):\n",
        "      self.d_model = input_shape[-1]\n",
        "\n",
        "      self.multi_head_attention = MultiHeadAttention(self.nb_proj)\n",
        "      self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
        "      self.norm_1 = layers.LayerNormalization(epsilon=1e-6) # 0.0000001\n",
        "\n",
        "      self.dense_1 = layers.Dense(units=self.FFN_units, activation='relu')\n",
        "      self.dense_2 = layers.Dense(units=self.d_model, activation='relu')\n",
        "      self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
        "\n",
        "      self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs, mask, training):\n",
        "      attention = self.multi_head_attention(inputs, inputs, inputs, mask)\n",
        "      attention = self.dropout_1(attention, training = training)\n",
        "      attention = self.norm_1(attention + inputs)\n",
        "\n",
        "      outputs = self.dense_1(attention)\n",
        "      outputs = self.dense_2(outputs)\n",
        "      outputs = self.dropout_2(outputs, training=training)\n",
        "      outputs = self.norm_2(outputs + attention)\n",
        "\n",
        "      return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-P92KeZih60"
      },
      "source": [
        "class Encoder(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"encoder\"):\n",
        "      super(Encoder, self).__init__(name=name)\n",
        "      self.nb_layers = nb_layers\n",
        "      self.d_model = d_model\n",
        "\n",
        "      self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "      self.pos_encoding = PositionalEncoding()\n",
        "      self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "      self.enc_layers = [EncoderLayer(FFN_units, nb_proj, dropout_rate) for _ in range(nb_layers)]\n",
        "\n",
        "\n",
        "    def call(self, inputs, mask, training):\n",
        "      outputs = self.embedding(inputs)\n",
        "      outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "      outputs = self.pos_encoding(outputs)\n",
        "      outputs = self.dropout(outputs, training)\n",
        "\n",
        "      for i in range(self.nb_layers):\n",
        "        outputs = self.enc_layers[i](outputs, mask, training)\n",
        "\n",
        "      return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DthraBEwuvl"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZWZyFBnwy8u"
      },
      "source": [
        "class DecoderLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, FFN_units, nb_proj, dropout_rate):\n",
        "      super(DecoderLayer, self).__init__()\n",
        "      self.FFN_units = FFN_units\n",
        "      self.nb_proj = nb_proj\n",
        "      self.dropout_rate = dropout_rate\n",
        "\n",
        "    def build(self, input_shape):\n",
        "      self.d_model = input_shape[-1]\n",
        "\n",
        "      self.multi_head_attention_1 = MultiHeadAttention(self.nb_proj)\n",
        "      self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
        "      self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "      self.multi_head_attention_2 = MultiHeadAttention(self.nb_proj)\n",
        "      self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
        "      self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "      self.dense_1 = layers.Dense(units = self.FFN_units, activation='relu')\n",
        "      self.dense_2 = layers.Dense(units = self.d_model, activation='relu')\n",
        "      self.dropout_3 = layers.Dropout(rate=self.dropout_rate)\n",
        "      self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
        "      attention = self.multi_head_attention_1(inputs, inputs, inputs, mask_1)\n",
        "      attention = self.dropout_1(attention, training)\n",
        "      attention = self.norm_1(attention + inputs)\n",
        "\n",
        "      attention_2 = self.multi_head_attention_2(attention, enc_outputs, enc_outputs, mask_2)\n",
        "      attention_2 = self.dropout_2(attention_2, training)\n",
        "      attention_2 = self.norm_2(attention_2 + attention)\n",
        "\n",
        "      outputs = self.dense_1(attention_2)\n",
        "      outputs = self.dense_2(outputs)\n",
        "      outputs = self.dropout_3(outputs, training)\n",
        "      outputs = self.norm_3(outputs + attention_2)\n",
        "\n",
        "      return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpzdiWHiwywF"
      },
      "source": [
        "class Decoder(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"decoder\"):\n",
        "      super(Decoder, self).__init__(name=name)\n",
        "      self.d_model = d_model\n",
        "      self.nb_layers = nb_layers\n",
        "\n",
        "      self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "      self.pos_encoding = PositionalEncoding()\n",
        "      self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "      self.dec_layers = [DecoderLayer(FFN_units, nb_proj, dropout_rate) for i in range(nb_layers)]\n",
        "\n",
        "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
        "      outputs = self.embedding(inputs)\n",
        "      outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "      outputs = self.pos_encoding(outputs)\n",
        "      outputs = self.dropout(outputs, training)\n",
        "\n",
        "      for i in range(self.nb_layers):\n",
        "        outputs = self.dec_layers[i](outputs, enc_outputs, mask_1, mask_2, training)\n",
        "\n",
        "      return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5sJYkjbz5DD"
      },
      "source": [
        "## Transformer\n",
        "\n",
        "- Matriz triangular: https://mundoeducacao.bol.uol.com.br/matematica/matriz-triangular.htm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqvqNjJPwyh-"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size_enc,\n",
        "                 vocab_size_dec,\n",
        "                 d_model,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout_rate,\n",
        "                 name=\"transformer\"):\n",
        "        super(Transformer, self).__init__(name=name)\n",
        "\n",
        "        self.encoder = Encoder(nb_layers, FFN_units, nb_proj, dropout_rate,\n",
        "                               vocab_size_enc, d_model)\n",
        "        self.decoder = Decoder(nb_layers, FFN_units, nb_proj, dropout_rate,\n",
        "                               vocab_size_dec, d_model)\n",
        "        self.last_linear = layers.Dense(units=vocab_size_dec, name='lin_output')\n",
        "\n",
        "    def create_padding_mask(self, seq): # (batch_size, seq_length) -> (batch_size, nb_proj, seq_lenght, d_proj)\n",
        "      mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "      return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    def create_look_ahead_mask(self, seq):\n",
        "      seq_len = tf.shape(seq)[1]\n",
        "      look_ahed_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "      return look_ahed_mask\n",
        "\n",
        "    def call(self, enc_inputs, dec_inputs, training):\n",
        "      enc_mask = self.create_padding_mask(enc_inputs)\n",
        "      dec_mask_1 = tf.maximum(self.create_padding_mask(dec_inputs), self.create_look_ahead_mask(dec_inputs))\n",
        "      dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
        "\n",
        "      enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n",
        "      dec_outputs = self.decoder(dec_inputs, enc_outputs, dec_mask_1, dec_mask_2, training)\n",
        "\n",
        "      outputs = self.last_linear(dec_outputs)\n",
        "\n",
        "      return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA9xWT8YQwop"
      },
      "source": [
        "## Código somente para testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUact3PNMdF8"
      },
      "source": [
        "# Código somente para testes\n",
        "\n",
        "def create_padding_mask(seq): # (batch_size, seq_length) -> (batch_size, nb_proj, seq_lenght, d_proj)\n",
        "  mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(seq):\n",
        "  seq_len = tf.shape(seq)[1]\n",
        "  look_ahed_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  return look_ahed_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq = tf.cast([[837, 836, 0, 273, 8, 0, 0, 0]], tf.int32)"
      ],
      "metadata": {
        "id": "VPabQR1cb-dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt17R_45NrXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b9bf66-d52c-4d1e-a752-8a94778ef4cd"
      },
      "source": [
        "create_padding_mask(seq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 1, 8), dtype=float32, numpy=array([[[[0., 0., 1., 0., 0., 1., 1., 1.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IrBb52AOZjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518cb2bf-a3be-461b-d286-c2636b13dfb6"
      },
      "source": [
        "create_look_ahead_mask(seq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 8), dtype=float32, numpy=\n",
              "array([[0., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oArT_ZqMMkuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8c3887-7cdd-4607-b58a-c593c87a69b8"
      },
      "source": [
        "tf.maximum(create_padding_mask(seq), create_look_ahead_mask(seq))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 8, 8), dtype=float32, numpy=\n",
              "array([[[[0., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 0., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 0., 0., 1., 1., 1.],\n",
              "         [0., 0., 1., 0., 0., 1., 1., 1.],\n",
              "         [0., 0., 1., 0., 0., 1., 1., 1.],\n",
              "         [0., 0., 1., 0., 0., 1., 1., 1.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c-LRThUPrso"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z1SYWDhQ-_m"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "d_model = 128 # 512\n",
        "nb_layers = 4 # 6\n",
        "ffn_units = 512 # 2048\n",
        "nb_proj = 8 # 8\n",
        "dropout_rate = 0.1 # 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLrkr3Z2xfB3"
      },
      "source": [
        "transformer = Transformer(vocab_size_enc=vocab_size_en,\n",
        "                          vocab_size_dec=vocab_size_pt,\n",
        "                          d_model=d_model,\n",
        "                          nb_layers=nb_layers,\n",
        "                          FFN_units=ffn_units,\n",
        "                          nb_proj=nb_proj,\n",
        "                          dropout_rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTJf8byN0Hc4"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipaSsj7f1A-a"
      },
      "source": [
        "def loss_function(target, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
        "  loss_ = loss_object(target, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0848DUA2Qer"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTtdQq4v2sN1"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = tf.cast(d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYA3kAnP4okk"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzawICsM40Gc"
      },
      "source": [
        "# ATUALIZAÇÃO MAR-2024\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeVrjXDZ6BN_"
      },
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/tradutor\"\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print('Latest checkpoint restored')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytr3z2nb7ICt"
      },
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  print('Start or epoch {}'.format(epoch + 1))\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  for (batch, (enc_inputs, targets)) in enumerate(dataset):\n",
        "    dec_inputs = targets[:, :-1]\n",
        "    dec_outputs_real = targets[:, 1:]\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = transformer(enc_inputs, dec_inputs, True)\n",
        "      loss = loss_function(dec_outputs_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(dec_outputs_real, predictions)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "  ckpt_save_path = ckpt_manager.save()\n",
        "  print('Saving checkpoint for epoch {} at {}'.format(epoch + 1, ckpt_save_path))\n",
        "  print('Time taken for 1 epoch {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmzyRwDrRGdq"
      },
      "source": [
        "# Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0pqI1RTpzwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e59bd6-e992-4e6c-a4e9-6fd1f97ce82e"
      },
      "source": [
        "text = 'you are smart'\n",
        "text = [vocab_size_en - 2] + tokenizer_en.encode(text) + [vocab_size_en - 1]\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8191, 55, 17, 2202, 4099, 8192]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvGS3gUJqHI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5246b1c0-b00a-409c-bc65-a350cf4722c3"
      },
      "source": [
        "text = tf.expand_dims(text, axis=0)\n",
        "text.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAS70m-xq9M5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba4e1fb-89c1-4aae-96d1-a9b73c76e9fd"
      },
      "source": [
        "output = tf.expand_dims([vocab_size_pt - 2], axis = 0)\n",
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDtQcdvHqcVi"
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "  inp_sentence = [vocab_size_en - 2] + tokenizer_en.encode(inp_sentence) + [vocab_size_en - 1]\n",
        "  enc_input = tf.expand_dims(inp_sentence, axis=0)\n",
        "\n",
        "  output = tf.expand_dims([vocab_size_pt - 2], axis = 0)\n",
        "\n",
        "  # i am -> am happy\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # (1, seq_length, vocab_size)\n",
        "    predictions = transformer(enc_input, output, False)\n",
        "    prediction = predictions[:, -1:, :]\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)\n",
        "\n",
        "    if predicted_id == vocab_size_pt - 1:\n",
        "      return tf.squeeze(output, axis=0)\n",
        "\n",
        "    output = tf.concat([output, predicted_id], axis=1)\n",
        "\n",
        "  return tf.squeeze(output, axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyAABcHRtcms"
      },
      "source": [
        "def translate(sentence):\n",
        "  output = evaluate(sentence).numpy()\n",
        "\n",
        "  predicted_sentence = tokenizer_pt.decode([i for i in output if i < vocab_size_pt - 2])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfLt3wZmt3wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43db0d13-7a04-43ec-dd98-7303c0ccea69"
      },
      "source": [
        "translate(\"this is a really powerful tool\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: this is a really powerful tool\n",
            "Predicted translation: Também isto é um instrumento podíssimo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8GrBzcCxDaF"
      },
      "source": [
        "Melhorias\n",
        "\n",
        "- Utilizar a base de dados completa\n",
        "- Aumentar o tamanho da frase\n",
        "- Mudar os parâmetros"
      ]
    }
  ]
}
